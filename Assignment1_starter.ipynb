{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment1_starter_edited.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dil34lm2V1T6"
      },
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "import pandas as pd\n",
        "import io"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB_0dFbHdrBg"
      },
      "source": [
        "# generating training dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "CHqtsBP8du2s",
        "outputId": "1a13f25c-38c7-41b0-e978-6899fd504b84"
      },
      "source": [
        "# upload file with dictionary format, with key as name of uploaded file \n",
        "# and corresponding values as the contens of the file \n",
        "from google.colab import files\n",
        "uploaded_train = files.upload()\n",
        "uploaded_test = files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4976424f-0aa8-475b-840c-1a40531fee47\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4976424f-0aa8-475b-840c-1a40531fee47\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Train_Data.txt to Train_Data.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f9f4e70f-c08a-48ad-8e00-993636bc1d86\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f9f4e70f-c08a-48ad-8e00-993636bc1d86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Test_Data.txt to Test_Data.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlNQjWYg-y6F",
        "outputId": "e529c296-4853-4fd0-fd36-287780d98e06"
      },
      "source": [
        "# use panda and io pachage to load txt. \n",
        "df_train = pd.read_csv(io.StringIO(uploaded_train['Train_Data.txt'].decode(\"utf-8\")), \n",
        "                       sep=',', names=['ID', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'class'], header=None)\n",
        "print(df_train)\n",
        "\n",
        "df_test = pd.read_csv(io.StringIO(uploaded_test['Test_Data.txt'].decode(\"utf-8\")), \n",
        "                       sep=',', names=['ID', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'class'], header=None)\n",
        "print(df_test)\n",
        "#replace missing value ? with 0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ID  x1  x2  x3  x4  x5  x6  x7  x8  x9  class\n",
            "0    1000025   5   1   1   1   2   1   3   1   1      2\n",
            "1    1002945   5   4   4   5   7  10   3   2   1      2\n",
            "2    1015425   3   1   1   1   2   2   3   1   1      2\n",
            "3    1016277   6   8   8   1   3   4   3   7   1      2\n",
            "4    1017023   4   1   1   3   2   1   3   1   1      2\n",
            "..       ...  ..  ..  ..  ..  ..  ..  ..  ..  ..    ...\n",
            "594  1315506   4   8   6   3   4  10   7   1   1      4\n",
            "595  1320141   5   1   1   1   2   1   2   1   1      2\n",
            "596  1325309   4   1   2   1   2   1   2   1   1      2\n",
            "597  1333063   5   1   3   1   2   1   3   1   1      2\n",
            "598  1333495   3   1   1   1   2   1   2   1   1      2\n",
            "\n",
            "[599 rows x 11 columns]\n",
            "         ID  x1  x2  x3  x4  x5 x6  x7  x8  x9  class\n",
            "0   1334659   5   2   4   1   1  1   1   1   1      2\n",
            "1   1336798   3   1   1   1   2  1   2   1   1      2\n",
            "2   1344449   1   1   1   1   1  1   2   1   1      2\n",
            "3   1350568   4   1   1   1   2  1   2   1   1      2\n",
            "4   1352663   5   4   6   8   4  1   8  10   1      4\n",
            "..      ...  ..  ..  ..  ..  .. ..  ..  ..  ..    ...\n",
            "95   776715   3   1   1   1   3  2   1   1   1      2\n",
            "96   841769   2   1   1   1   2  1   1   1   1      2\n",
            "97   888820   5  10  10   3   7  3   8  10   2      4\n",
            "98   897471   4   8   6   4   3  4  10   6   1      4\n",
            "99   897471   4   8   8   5   4  5  10   4   1      4\n",
            "\n",
            "[100 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXYIBh9jw9Hq"
      },
      "source": [
        "## Feature Selection or Manipulation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsHFLJ9oulM2",
        "outputId": "096336de-cc4c-4f15-bafd-ec81496023b6"
      },
      "source": [
        "X = df_train[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']].replace({'?':0})\n",
        "# print(X['x6'][0:10])\n",
        "\n",
        "y = df_train['class'].replace({2:0, 4:1})\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "\n",
        "x_train = torch.Tensor(np.array([X['x1'], X['x2']]).astype(np.uint8)).t()  # str to unit, [3, 500] ->  [500, 3]\n",
        "print(x_train.shape)\n",
        "\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "y_train = torch.Tensor(y).unsqueeze(1) # [500] -> [500, 1]\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([599, 2])\n",
            "torch.Size([599, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZbQkpxkhH6G"
      },
      "source": [
        "# Define model class\n",
        "z = w1*x1 + w2*x2 + w3*x3 ....  + w6*x6 + b  -> <br>\n",
        "y = a = sigma(z) -> <br>\n",
        "L(y_hat = a, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWDgg8yEhFMk",
        "outputId": "a08a3d6e-4fe8-4885-805f-321789ff1340"
      },
      "source": [
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "  def forward(self, x): \n",
        "    pred = torch.sigmoid(self.linear(x))\n",
        "    return pred   #probability (not direct value)\n",
        "\n",
        "  def predict(self, x):\n",
        "    pred = self.forward(x)\n",
        "    if pred >= 0.5:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "print(x_train.shape)\n",
        "\n",
        "# instantiate model class\n",
        "torch.manual_seed(1)\n",
        "model = LogisticRegression(x_train.shape[1], 1) # [500, 2]\n",
        "print(list(model.parameters()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([599, 2])\n",
            "[Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1371], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08wLbfEljkE8"
      },
      "source": [
        "# function to get model parameters (w1, w2, b)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJX7kArljiPZ",
        "outputId": "74acca4b-484f-42e7-b882-e247c43abc0d"
      },
      "source": [
        "[w, b] = model.parameters() # Ws, bias\n",
        "print(w) \n",
        "w1, w2= w.view(x_train.shape[1])\n",
        "\n",
        "def get_params():\n",
        "  return (w1.item(), w2.item(), b[0].item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.3643, -0.3121]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gkj4yqKlgcA"
      },
      "source": [
        "# training the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkW2eQbklixb",
        "outputId": "630ccf9c-ed03-48cb-a6ec-d60e98c9174d"
      },
      "source": [
        "# instantitate optimizer \n",
        "criterion = nn.BCELoss()  # = nn.CrossEntropyLoss() # for LR with more than 2 classes\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.02, momentum=0.9) #weight_decay=1e-5 -> L2 regularizer\n",
        "\n",
        "# training the model \n",
        "epochs = 300\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  y_pred = model.forward(x_train)\n",
        "\n",
        "  # calculate loss \n",
        "  loss = criterion(y_pred, y_train)\n",
        "\n",
        "  # L2 regularizer\n",
        "  l_lambda = 0.01\n",
        "  l_reg = torch.tensor(0.)\n",
        "  for param in model.parameters():\n",
        "      l_reg += torch.norm(param)  # for L1 regularizer : torch.norm(param, 1) \n",
        "  loss += l_lambda * l_reg\n",
        "\n",
        "  print(\"epoch: \", i, \"loss: \", loss.item())\n",
        "  losses.append(loss.item())\n",
        "\n",
        "  optimizer.zero_grad() # clear gradients wrt parameters\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 loss:  0.8781248331069946\n",
            "epoch:  1 loss:  0.8680179715156555\n",
            "epoch:  2 loss:  0.8492926359176636\n",
            "epoch:  3 loss:  0.8236404061317444\n",
            "epoch:  4 loss:  0.7928182482719421\n",
            "epoch:  5 loss:  0.7585664391517639\n",
            "epoch:  6 loss:  0.7225825190544128\n",
            "epoch:  7 loss:  0.6865124702453613\n",
            "epoch:  8 loss:  0.6519100069999695\n",
            "epoch:  9 loss:  0.6201505661010742\n",
            "epoch:  10 loss:  0.5923120379447937\n",
            "epoch:  11 loss:  0.568833589553833\n",
            "epoch:  12 loss:  0.5494000911712646\n",
            "epoch:  13 loss:  0.53342604637146\n",
            "epoch:  14 loss:  0.5203176736831665\n",
            "epoch:  15 loss:  0.5095625519752502\n",
            "epoch:  16 loss:  0.5007416605949402\n",
            "epoch:  17 loss:  0.49350088834762573\n",
            "epoch:  18 loss:  0.48752135038375854\n",
            "epoch:  19 loss:  0.4825100600719452\n",
            "epoch:  20 loss:  0.4782044291496277\n",
            "epoch:  21 loss:  0.4743832051753998\n",
            "epoch:  22 loss:  0.47087275981903076\n",
            "epoch:  23 loss:  0.4675474762916565\n",
            "epoch:  24 loss:  0.46432316303253174\n",
            "epoch:  25 loss:  0.4611468017101288\n",
            "epoch:  26 loss:  0.45798608660697937\n",
            "epoch:  27 loss:  0.45482051372528076\n",
            "epoch:  28 loss:  0.45163580775260925\n",
            "epoch:  29 loss:  0.44842055439949036\n",
            "epoch:  30 loss:  0.4451673626899719\n",
            "epoch:  31 loss:  0.4418724775314331\n",
            "epoch:  32 loss:  0.4385372996330261\n",
            "epoch:  33 loss:  0.43516799807548523\n",
            "epoch:  34 loss:  0.4317743182182312\n",
            "epoch:  35 loss:  0.42836833000183105\n",
            "epoch:  36 loss:  0.42496225237846375\n",
            "epoch:  37 loss:  0.42156723141670227\n",
            "epoch:  38 loss:  0.41819238662719727\n",
            "epoch:  39 loss:  0.41484537720680237\n",
            "epoch:  40 loss:  0.41153252124786377\n",
            "epoch:  41 loss:  0.40825966000556946\n",
            "epoch:  42 loss:  0.40503260493278503\n",
            "epoch:  43 loss:  0.4018574059009552\n",
            "epoch:  44 loss:  0.39874014258384705\n",
            "epoch:  45 loss:  0.39568623900413513\n",
            "epoch:  46 loss:  0.3927004933357239\n",
            "epoch:  47 loss:  0.3897861838340759\n",
            "epoch:  48 loss:  0.38694560527801514\n",
            "epoch:  49 loss:  0.38417962193489075\n",
            "epoch:  50 loss:  0.38148850202560425\n",
            "epoch:  51 loss:  0.37887197732925415\n",
            "epoch:  52 loss:  0.37632977962493896\n",
            "epoch:  53 loss:  0.3738611340522766\n",
            "epoch:  54 loss:  0.3714655041694641\n",
            "epoch:  55 loss:  0.36914193630218506\n",
            "epoch:  56 loss:  0.3668888509273529\n",
            "epoch:  57 loss:  0.36470454931259155\n",
            "epoch:  58 loss:  0.36258670687675476\n",
            "epoch:  59 loss:  0.36053261160850525\n",
            "epoch:  60 loss:  0.35853978991508484\n",
            "epoch:  61 loss:  0.3566054403781891\n",
            "epoch:  62 loss:  0.35472699999809265\n",
            "epoch:  63 loss:  0.3529019355773926\n",
            "epoch:  64 loss:  0.35112789273262024\n",
            "epoch:  65 loss:  0.3494025468826294\n",
            "epoch:  66 loss:  0.3477235734462738\n",
            "epoch:  67 loss:  0.3460886478424072\n",
            "epoch:  68 loss:  0.3444955050945282\n",
            "epoch:  69 loss:  0.34294188022613525\n",
            "epoch:  70 loss:  0.3414258658885956\n",
            "epoch:  71 loss:  0.3399454653263092\n",
            "epoch:  72 loss:  0.33849895000457764\n",
            "epoch:  73 loss:  0.33708494901657104\n",
            "epoch:  74 loss:  0.3357017934322357\n",
            "epoch:  75 loss:  0.3343483805656433\n",
            "epoch:  76 loss:  0.33302342891693115\n",
            "epoch:  77 loss:  0.33172571659088135\n",
            "epoch:  78 loss:  0.3304542601108551\n",
            "epoch:  79 loss:  0.32920801639556885\n",
            "epoch:  80 loss:  0.32798609137535095\n",
            "epoch:  81 loss:  0.32678771018981934\n",
            "epoch:  82 loss:  0.3256121575832367\n",
            "epoch:  83 loss:  0.3244587779045105\n",
            "epoch:  84 loss:  0.3233269453048706\n",
            "epoch:  85 loss:  0.32221609354019165\n",
            "epoch:  86 loss:  0.32112568616867065\n",
            "epoch:  87 loss:  0.3200552761554718\n",
            "epoch:  88 loss:  0.31900423765182495\n",
            "epoch:  89 loss:  0.31797224283218384\n",
            "epoch:  90 loss:  0.3169586956501007\n",
            "epoch:  91 loss:  0.31596335768699646\n",
            "epoch:  92 loss:  0.3149856626987457\n",
            "epoch:  93 loss:  0.3140253722667694\n",
            "epoch:  94 loss:  0.3130820095539093\n",
            "epoch:  95 loss:  0.31215527653694153\n",
            "epoch:  96 loss:  0.31124475598335266\n",
            "epoch:  97 loss:  0.31035012006759644\n",
            "epoch:  98 loss:  0.3094710409641266\n",
            "epoch:  99 loss:  0.3086070716381073\n",
            "epoch:  100 loss:  0.30775803327560425\n",
            "epoch:  101 loss:  0.306923508644104\n",
            "epoch:  102 loss:  0.3061031997203827\n",
            "epoch:  103 loss:  0.30529677867889404\n",
            "epoch:  104 loss:  0.30450400710105896\n",
            "epoch:  105 loss:  0.303724467754364\n",
            "epoch:  106 loss:  0.3029579818248749\n",
            "epoch:  107 loss:  0.30220410227775574\n",
            "epoch:  108 loss:  0.30146270990371704\n",
            "epoch:  109 loss:  0.30073344707489014\n",
            "epoch:  110 loss:  0.3000160753726959\n",
            "epoch:  111 loss:  0.2993103265762329\n",
            "epoch:  112 loss:  0.2986159026622772\n",
            "epoch:  113 loss:  0.29793262481689453\n",
            "epoch:  114 loss:  0.29726019501686096\n",
            "epoch:  115 loss:  0.2965983748435974\n",
            "epoch:  116 loss:  0.29594701528549194\n",
            "epoch:  117 loss:  0.2953057289123535\n",
            "epoch:  118 loss:  0.29467448592185974\n",
            "epoch:  119 loss:  0.29405298829078674\n",
            "epoch:  120 loss:  0.2934409976005554\n",
            "epoch:  121 loss:  0.29283827543258667\n",
            "epoch:  122 loss:  0.2922448217868805\n",
            "epoch:  123 loss:  0.29166021943092346\n",
            "epoch:  124 loss:  0.2910844683647156\n",
            "epoch:  125 loss:  0.2905172109603882\n",
            "epoch:  126 loss:  0.2899584472179413\n",
            "epoch:  127 loss:  0.289407879114151\n",
            "epoch:  128 loss:  0.28886544704437256\n",
            "epoch:  129 loss:  0.28833088278770447\n",
            "epoch:  130 loss:  0.2878040373325348\n",
            "epoch:  131 loss:  0.287284791469574\n",
            "epoch:  132 loss:  0.28677308559417725\n",
            "epoch:  133 loss:  0.2862686514854431\n",
            "epoch:  134 loss:  0.28577134013175964\n",
            "epoch:  135 loss:  0.28528112173080444\n",
            "epoch:  136 loss:  0.2847977578639984\n",
            "epoch:  137 loss:  0.2843211889266968\n",
            "epoch:  138 loss:  0.2838512063026428\n",
            "epoch:  139 loss:  0.28338783979415894\n",
            "epoch:  140 loss:  0.28293079137802124\n",
            "epoch:  141 loss:  0.28248000144958496\n",
            "epoch:  142 loss:  0.2820354104042053\n",
            "epoch:  143 loss:  0.2815968692302704\n",
            "epoch:  144 loss:  0.2811642587184906\n",
            "epoch:  145 loss:  0.28073742985725403\n",
            "epoch:  146 loss:  0.2803162932395935\n",
            "epoch:  147 loss:  0.27990084886550903\n",
            "epoch:  148 loss:  0.2794908881187439\n",
            "epoch:  149 loss:  0.2790863513946533\n",
            "epoch:  150 loss:  0.27868711948394775\n",
            "epoch:  151 loss:  0.2782931327819824\n",
            "epoch:  152 loss:  0.2779042720794678\n",
            "epoch:  153 loss:  0.27752047777175903\n",
            "epoch:  154 loss:  0.27714163064956665\n",
            "epoch:  155 loss:  0.27676764130592346\n",
            "epoch:  156 loss:  0.2763984203338623\n",
            "epoch:  157 loss:  0.2760339379310608\n",
            "epoch:  158 loss:  0.27567407488822937\n",
            "epoch:  159 loss:  0.2753187417984009\n",
            "epoch:  160 loss:  0.27496787905693054\n",
            "epoch:  161 loss:  0.27462145686149597\n",
            "epoch:  162 loss:  0.27427929639816284\n",
            "epoch:  163 loss:  0.2739414572715759\n",
            "epoch:  164 loss:  0.27360770106315613\n",
            "epoch:  165 loss:  0.2732781171798706\n",
            "epoch:  166 loss:  0.2729525566101074\n",
            "epoch:  167 loss:  0.2726309895515442\n",
            "epoch:  168 loss:  0.27231329679489136\n",
            "epoch:  169 loss:  0.2719995081424713\n",
            "epoch:  170 loss:  0.27168944478034973\n",
            "epoch:  171 loss:  0.271383136510849\n",
            "epoch:  172 loss:  0.27108046412467957\n",
            "epoch:  173 loss:  0.27078142762184143\n",
            "epoch:  174 loss:  0.27048593759536743\n",
            "epoch:  175 loss:  0.2701939046382904\n",
            "epoch:  176 loss:  0.26990532875061035\n",
            "epoch:  177 loss:  0.2696201801300049\n",
            "epoch:  178 loss:  0.2693382799625397\n",
            "epoch:  179 loss:  0.2690597176551819\n",
            "epoch:  180 loss:  0.26878437399864197\n",
            "epoch:  181 loss:  0.26851218938827515\n",
            "epoch:  182 loss:  0.2682431638240814\n",
            "epoch:  183 loss:  0.267977237701416\n",
            "epoch:  184 loss:  0.26771432161331177\n",
            "epoch:  185 loss:  0.2674543261528015\n",
            "epoch:  186 loss:  0.2671973407268524\n",
            "epoch:  187 loss:  0.2669432759284973\n",
            "epoch:  188 loss:  0.26669204235076904\n",
            "epoch:  189 loss:  0.2664436101913452\n",
            "epoch:  190 loss:  0.26619797945022583\n",
            "epoch:  191 loss:  0.2659550607204437\n",
            "epoch:  192 loss:  0.2657148241996765\n",
            "epoch:  193 loss:  0.2654772400856018\n",
            "epoch:  194 loss:  0.265242338180542\n",
            "epoch:  195 loss:  0.26500990986824036\n",
            "epoch:  196 loss:  0.26478004455566406\n",
            "epoch:  197 loss:  0.2645527124404907\n",
            "epoch:  198 loss:  0.26432785391807556\n",
            "epoch:  199 loss:  0.2641054093837738\n",
            "epoch:  200 loss:  0.2638853192329407\n",
            "epoch:  201 loss:  0.26366767287254333\n",
            "epoch:  202 loss:  0.26345229148864746\n",
            "epoch:  203 loss:  0.2632392644882202\n",
            "epoch:  204 loss:  0.26302841305732727\n",
            "epoch:  205 loss:  0.26281991600990295\n",
            "epoch:  206 loss:  0.26261353492736816\n",
            "epoch:  207 loss:  0.2624093294143677\n",
            "epoch:  208 loss:  0.2622072696685791\n",
            "epoch:  209 loss:  0.26200732588768005\n",
            "epoch:  210 loss:  0.26180946826934814\n",
            "epoch:  211 loss:  0.2616136372089386\n",
            "epoch:  212 loss:  0.26141980290412903\n",
            "epoch:  213 loss:  0.2612280547618866\n",
            "epoch:  214 loss:  0.26103824377059937\n",
            "epoch:  215 loss:  0.26085034012794495\n",
            "epoch:  216 loss:  0.2606644034385681\n",
            "epoch:  217 loss:  0.2604803442955017\n",
            "epoch:  218 loss:  0.26029813289642334\n",
            "epoch:  219 loss:  0.260117769241333\n",
            "epoch:  220 loss:  0.2599392533302307\n",
            "epoch:  221 loss:  0.2597624957561493\n",
            "epoch:  222 loss:  0.2595875859260559\n",
            "epoch:  223 loss:  0.25941431522369385\n",
            "epoch:  224 loss:  0.25924280285835266\n",
            "epoch:  225 loss:  0.25907304883003235\n",
            "epoch:  226 loss:  0.25890493392944336\n",
            "epoch:  227 loss:  0.2587384879589081\n",
            "epoch:  228 loss:  0.2585736811161041\n",
            "epoch:  229 loss:  0.2584104835987091\n",
            "epoch:  230 loss:  0.25824886560440063\n",
            "epoch:  231 loss:  0.2580888271331787\n",
            "epoch:  232 loss:  0.25793036818504333\n",
            "epoch:  233 loss:  0.25777342915534973\n",
            "epoch:  234 loss:  0.2576180100440979\n",
            "epoch:  235 loss:  0.25746411085128784\n",
            "epoch:  236 loss:  0.25731170177459717\n",
            "epoch:  237 loss:  0.2571606934070587\n",
            "epoch:  238 loss:  0.25701114535331726\n",
            "epoch:  239 loss:  0.2568630278110504\n",
            "epoch:  240 loss:  0.25671637058258057\n",
            "epoch:  241 loss:  0.2565709948539734\n",
            "epoch:  242 loss:  0.2564271092414856\n",
            "epoch:  243 loss:  0.2562845051288605\n",
            "epoch:  244 loss:  0.2561432719230652\n",
            "epoch:  245 loss:  0.25600332021713257\n",
            "epoch:  246 loss:  0.255864679813385\n",
            "epoch:  247 loss:  0.2557273507118225\n",
            "epoch:  248 loss:  0.25559133291244507\n",
            "epoch:  249 loss:  0.2554565370082855\n",
            "epoch:  250 loss:  0.25532299280166626\n",
            "epoch:  251 loss:  0.2551907002925873\n",
            "epoch:  252 loss:  0.2550595700740814\n",
            "epoch:  253 loss:  0.25492966175079346\n",
            "epoch:  254 loss:  0.2548010051250458\n",
            "epoch:  255 loss:  0.25467348098754883\n",
            "epoch:  256 loss:  0.2545470893383026\n",
            "epoch:  257 loss:  0.2544218897819519\n",
            "epoch:  258 loss:  0.25429776310920715\n",
            "epoch:  259 loss:  0.25417476892471313\n",
            "epoch:  260 loss:  0.2540529668331146\n",
            "epoch:  261 loss:  0.2539321780204773\n",
            "epoch:  262 loss:  0.2538124918937683\n",
            "epoch:  263 loss:  0.2536938190460205\n",
            "epoch:  264 loss:  0.25357627868652344\n",
            "epoch:  265 loss:  0.25345975160598755\n",
            "epoch:  266 loss:  0.25334426760673523\n",
            "epoch:  267 loss:  0.2532298266887665\n",
            "epoch:  268 loss:  0.25311633944511414\n",
            "epoch:  269 loss:  0.25300389528274536\n",
            "epoch:  270 loss:  0.252892404794693\n",
            "epoch:  271 loss:  0.2527818977832794\n",
            "epoch:  272 loss:  0.252672404050827\n",
            "epoch:  273 loss:  0.25256383419036865\n",
            "epoch:  274 loss:  0.2524561882019043\n",
            "epoch:  275 loss:  0.25234946608543396\n",
            "epoch:  276 loss:  0.25224369764328003\n",
            "epoch:  277 loss:  0.25213882327079773\n",
            "epoch:  278 loss:  0.25203487277030945\n",
            "epoch:  279 loss:  0.2519317865371704\n",
            "epoch:  280 loss:  0.251829594373703\n",
            "epoch:  281 loss:  0.2517282962799072\n",
            "epoch:  282 loss:  0.2516278624534607\n",
            "epoch:  283 loss:  0.251528263092041\n",
            "epoch:  284 loss:  0.2514294981956482\n",
            "epoch:  285 loss:  0.2513315975666046\n",
            "epoch:  286 loss:  0.2512345016002655\n",
            "epoch:  287 loss:  0.25113824009895325\n",
            "epoch:  288 loss:  0.25104278326034546\n",
            "epoch:  289 loss:  0.25094813108444214\n",
            "epoch:  290 loss:  0.2508542537689209\n",
            "epoch:  291 loss:  0.25076115131378174\n",
            "epoch:  292 loss:  0.25066888332366943\n",
            "epoch:  293 loss:  0.25057733058929443\n",
            "epoch:  294 loss:  0.2504865229129791\n",
            "epoch:  295 loss:  0.2503965198993683\n",
            "epoch:  296 loss:  0.25030720233917236\n",
            "epoch:  297 loss:  0.2502186894416809\n",
            "epoch:  298 loss:  0.25013086199760437\n",
            "epoch:  299 loss:  0.2500437796115875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "rYkUBuB2lfiU",
        "outputId": "63fd9966-cd89-4766-e515-ccc7f031fa95"
      },
      "source": [
        "# log loss\n",
        "plt.plot(range(epochs), losses)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80NQ8m48n8fM"
      },
      "source": [
        "# model evalation with new datasets the model has never seen before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReUhXQhwFygw",
        "outputId": "5e4ceb1c-2d22-42ac-e150-641e339fb91f"
      },
      "source": [
        "X_test = df_test[['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9']].replace({'?':0})\n",
        "Y_test = df_test['class'].replace({2:0, 4:1})\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "\n",
        "x_test = torch.Tensor(np.array([X_test['x1'], X_test['x2']]).astype(np.uint8)).t()  # str to unit, [3, 500] ->  [500, 3]\n",
        "print(x_test.shape)\n",
        "# class 2 for benign, 4 for malignant -> 0 for bengn, 1 for malignant\n",
        "y_test = torch.Tensor(Y_test).unsqueeze(1) # [500] -> [500, 1]\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 2])\n",
            "torch.Size([100, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZcMsmzQHERY",
        "outputId": "a9f0c53c-78e0-4b18-912f-96da18aec51b"
      },
      "source": [
        "#model test w/ all test datasets\n",
        "no_correct = 0\n",
        "for i in range(len(x_train)):\n",
        "  if model.predict(x_train[i]) == y_train[i]:\n",
        "    no_correct += 1\n",
        "\n",
        "accuracy = no_correct/len(x_train)*100\n",
        "print(\"Predcition accuracy_train= {}%\".format(accuracy))\n",
        "\n",
        "no_correct_test=0\n",
        "for i in range(len(x_test)):\n",
        "  if model.predict(x_test[i]) == y_test[i]:\n",
        "    no_correct_test += 1\n",
        "\n",
        "accuracy = no_correct_test/len(x_test)*100\n",
        "\n",
        "print(\"Predcition accuracy_test= {}%\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predcition accuracy_train= 93.32220367278798%\n",
            "Predcition accuracy_test= 98.0%\n"
          ]
        }
      ]
    }
  ]
}